{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASTW7WC2MuwC"
   },
   "source": [
    "### Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1728607701286,
     "user": {
      "displayName": "en21491030 Perera G.P.B",
      "userId": "14306200759934344095"
     },
     "user_tz": -330
    },
    "id": "vbN4TEmiMw45"
   },
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from shapely.geometry import box, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model\n",
    "model = YOLO('TRAINING/traffic_detection/weights/best.pt')  #define the trained model directory\n",
    "\n",
    "# Defining the polygon for the Detection Zone\n",
    "polygon = np.array([[0, 432], [380, 161], [506, 184], [310, 508]])\n",
    "zone_polygon = Polygon(polygon)  \n",
    "\n",
    "# Initiating tracking with ByteTrack\n",
    "tracker = sv.ByteTrack(\n",
    "    track_activation_threshold=0.15,\n",
    "    lost_track_buffer=50,\n",
    "    minimum_matching_threshold=0.8,\n",
    "    frame_rate=8,\n",
    "    minimum_consecutive_frames=2\n",
    ")\n",
    "\n",
    "# Defining annotators\n",
    "box_annotator = sv.BoundingBoxAnnotator(thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=1, text_scale=0.5)\n",
    "\n",
    "# Storing vehicle states\n",
    "vehicle_states = {}\n",
    "threshold = 5               # Threshold to identify the vehicle motion status\n",
    "area_threshold = 0.05       # Threshold to consider a vehicle inside the detection zone\n",
    "max_rows = 15  \n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('inference/test1.mp4')   #define the sample video directory\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to identify vehicle motion status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_vehicle_stopped(last_pos, current_pos, threshold):\n",
    "    \"\"\"Check if the vehicle's position has changed beyond the threshold.\"\"\"\n",
    "    dist = np.linalg.norm(np.array(current_pos) - np.array(last_pos))\n",
    "    return dist < threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to identify detections inside the zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_detection_in_zone(bbox, zone_polygon, area_threshold):\n",
    "    \"\"\"Check if the bounding box area inside the zone polygon exceeds the threshold.\"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    bbox_polygon = box(x_min, y_min, x_max, y_max)                       # Create bounding box as Shapely box\n",
    "    intersection_area = bbox_polygon.intersection(zone_polygon).area     # Calculate intersection area\n",
    "    bbox_area = bbox_polygon.area                                        # Calculate bounding box area\n",
    "    return (intersection_area / bbox_area) > area_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callback function to execute \"Vehicle Count\" and \"Vehicle Stopped Delay Time\" extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def callback(frame: np.ndarray, _: int) -> np.ndarray:\n",
    "    global vehicle_states\n",
    "    results = model(frame)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    detections = tracker.update_with_detections(detections)\n",
    "\n",
    "    labels = []\n",
    "    active_ids = set()  # Tracking active tracker IDs in the Detection Zone\n",
    "    vehicle_count = 0   # Initialize vehicle counter for this frame\n",
    "\n",
    "    # Filter detections based on area overlap\n",
    "    filtered_boxes = []\n",
    "    filtered_labels = []\n",
    "    for tracker_id, class_id, xyxy in zip(detections.tracker_id, detections.class_id, detections.xyxy):\n",
    "        class_name = results.names[class_id]\n",
    "        tracker_id = int(tracker_id)\n",
    "        cx, cy = (xyxy[0] + xyxy[2]) / 2, (xyxy[1] + xyxy[3]) / 2       # Bounding Box Centroid\n",
    "\n",
    "        # Check if detection is within the zone based on area threshold\n",
    "        if is_detection_in_zone(xyxy, zone_polygon, area_threshold):\n",
    "            vehicle_count += 1              # Increment vehicle count if within zone\n",
    "            active_ids.add(tracker_id)      # Mark as active only if within zone\n",
    "\n",
    "            # Tracking vehicle state for delay calculation\n",
    "            if tracker_id not in vehicle_states:\n",
    "                vehicle_states[tracker_id] = {\"position\": (cx, cy), \"stopped_frames\": 0, \"is_stopped\": False}\n",
    "\n",
    "            vehicle_info = vehicle_states[tracker_id]\n",
    "\n",
    "            # Checking if vehicle is stopped\n",
    "            if is_vehicle_stopped(vehicle_info[\"position\"], (cx, cy), threshold):\n",
    "                if not vehicle_info[\"is_stopped\"]:\n",
    "                    vehicle_info[\"is_stopped\"] = True\n",
    "                vehicle_info[\"stopped_frames\"] += 1\n",
    "            else:\n",
    "                if vehicle_info[\"is_stopped\"]:\n",
    "                    vehicle_info[\"is_stopped\"] = False\n",
    "                    vehicle_info[\"stopped_frames\"] = 0\n",
    "\n",
    "            # Update position and prepare label continously across frames\n",
    "            vehicle_info[\"position\"] = (cx, cy)\n",
    "            labels.append(f\"#{tracker_id} {class_name}\")\n",
    "\n",
    "            # Collect filtered detections and labels\n",
    "            filtered_boxes.append(xyxy)\n",
    "            filtered_labels.append(f\"#{tracker_id} {class_name}\")\n",
    "\n",
    "    # Only annotate if there are filtered detections\n",
    "    if filtered_boxes:\n",
    "        # Create filtered detections\n",
    "        filtered_detections = sv.Detections.from_ultralytics(results)\n",
    "        filtered_detections.xyxy = np.array(filtered_boxes)\n",
    "        filtered_detections.tracker_id = [tracker_id for tracker_id in active_ids]\n",
    "        filtered_detections.class_id = [class_id for _, class_id, _ in zip(filtered_detections.tracker_id, detections.class_id, filtered_boxes)]\n",
    "\n",
    "        # Annotate filtered bounding boxes and labels on the frame\n",
    "        frame = box_annotator.annotate(scene=frame.copy(), detections=filtered_detections)\n",
    "        frame = label_annotator.annotate(scene=frame.copy(), detections=filtered_detections, labels=filtered_labels)\n",
    "\n",
    "    # Visualizing the detection zone\n",
    "    cv2.polylines(frame, [polygon], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # Visualizing vehicle count in the middle of the detection zone\n",
    "    center_x, center_y = np.mean(polygon, axis=0).astype(int)\n",
    "    count_text = f\"Count: {vehicle_count}\"\n",
    "    (text_width, text_height), _ = cv2.getTextSize(count_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "    cv2.rectangle(frame, \n",
    "                  (center_x - text_width // 2 - 5, center_y - text_height // 2 - 5), \n",
    "                  (center_x + text_width // 2 + 5, center_y + text_height // 2 + 5), \n",
    "                  (0, 255, 0), -1)\n",
    "    cv2.putText(frame, count_text, (center_x - text_width // 2, center_y + text_height // 2), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Visualizing individual stopped delay times\n",
    "    delay_table = [\"\"] * max_rows\n",
    "    row = 0\n",
    "    for tracker_id, vehicle_info in vehicle_states.items():\n",
    "        if tracker_id in active_ids:\n",
    "            delay_time = vehicle_info[\"stopped_frames\"] / fps\n",
    "            if vehicle_info[\"is_stopped\"]:\n",
    "                delay_text = f\"Vehicle {tracker_id}: {delay_time:.2f}s\"\n",
    "            else:\n",
    "                delay_text = f\"Vehicle {tracker_id}: Moving\"\n",
    "\n",
    "            if row < max_rows:\n",
    "                delay_table[row] = delay_text  \n",
    "                row += 1\n",
    "    for i, text in enumerate(delay_table):\n",
    "        if text:  \n",
    "            cv2.putText(frame, text, (frame.shape[1] - 200, 50 + i * 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.process_video(source_path='inference/inference6.mp4', target_path='final/inference6.mp4', callback=callback)     #define the path location to save the output video"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "dr9g0G2YlaWZ",
    "K7iFH3deddcl",
    "Ly0sQVspBjme"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
